\section{Experiments}
\sean{Introduction to various experiments. Description of data sets.}
In this section we demonstrate the effectiveness of our selection and integration approaches on sets of both synthetic and real data.  We extracted 14,000 labeled citations from DBLP \sean{footnote 1} and 500,000 from the PubMed database \sean{footnote 2}.  For unlabeled testing data, we extracted and concatenated text from each of the available fields.  Order of fields was occasionally mixed in keeping with real-life inconsistency of citation structure.

\subsection{Synthetic Experiments}
\subsubsection{Selection}
\sean{Exp1: Comparison of clustering algorithms.}

\sean{Exp2: Comparison of ranking/seeding functions.}

\sean{Exp3: Accuracy before and after introduction of crowd edits and clamped inference}

\subsubsection{Integration}
\sean{Describe process for producing synthetic workload and justify simplifying assumptions.}

\sean{Exp4: DS vs. MV vs. Bayes for varying number of Turkers.}

\sean{Exp5: DS vs. MV vs. Bayes for varying levels of mean Turker quality.}

\sean{Exp6: Recall vs. accuracy for varying entropy thresholds.}

\subsection{Real Experiments}
\sean{Description of real experiment methodology.}

\sean{Exp7: Table of accuracy comparisons for DS, MV, and Bayes before and after edits plus clamped inference for both data sets.}

\sean{Exp8: Recall vs. accuracy for varying entropy thresholds for both data sets.}
